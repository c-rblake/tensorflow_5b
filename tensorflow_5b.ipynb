{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we go Revisiting the 5A project \n",
    "The 5A project aimed to find a solution to life expectancy given some features. <br>\n",
    "To set the bar higher from project 5A, I have made a stronger model in another program of mine optimized for the 5A project. This optimized model is also given here by the function viking<br>\n",
    "In 5A we excluded some data, we are going to revisit that data without an optimized model, but not fit to that data at all. In so doing we see the robustness to outliers most likely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"Life Expectancy Data.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "df['Relative Expenditure'] = df['Total expenditure'] / df['GDP']\n",
    "df = df.drop(labels=['Country','Year','GDP'], axis=1)\n",
    "df = df.dropna()\n",
    "df['Status'] = df['Status'].apply(lambda x: 1 if x == 'Developing' else 0)\n",
    "target = df.pop('Life expectancy')\n",
    "features = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = features.select_dtypes(['float64','int64'])\n",
    "numeric_columns = numeric_features.columns\n",
    "ct = ColumnTransformer([(\"Numeric Scaler\", StandardScaler(), numeric_columns)], remainder='passthrough')\n",
    "# We want to standardize or normalize the data, or many other litte math features such as L1, L2 wont go at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, train_size=0.8)\n",
    "X_train_scaled = ct.fit_transform(X_train)\n",
    "X_test_scaled = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viking():\n",
    "    my_model = Sequential(name='Model_Viking')\n",
    "    input_layer = Input(shape=(features.shape[1],), name='input_layer')\n",
    "    my_model.add(input_layer)\n",
    "\n",
    "    dense_1 = Dense(32, activation='relu', name='hidden_layer_one')\n",
    "    dense_2 = Dense(32, activation='relu', name='hidden_layer_two')\n",
    "    my_model.add(dense_1)\n",
    "    my_model.add(dense_2)\n",
    "\n",
    "    output_layer = Dense(1, name='regression_output')\n",
    "    my_model.add(output_layer)\n",
    "    \n",
    "    my_model.compile(loss='mse',metrics=['mae'], optimizer='Adam')\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_Viking\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_one (Dense)     (None, 32)                640       \n",
      "_________________________________________________________________\n",
      "hidden_layer_two (Dense)     (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "regression_output (Dense)    (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,729\n",
      "Trainable params: 1,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "my_model = viking()\n",
    "print(my_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = my_model.fit(X_train_scaled, y_train, epochs=97, batch_size=4, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/330 [==============================] - 0s 232us/sample - loss: 6.6559 - mae: 1.8250\n"
     ]
    }
   ],
   "source": [
    "res_mse, res_mae = my_model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.66\n",
      "Mean Absolute Error: 1.83\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Squared Error: {np.round(res_mse, decimals=2)}\")\n",
    "print(f\"Mean Absolute Error:\", np.round(res_mae, decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An even tougher baseline to beat.\n",
    "In project 5A the losses were about: \n",
    "* Mean Squared Error: 7.69 <br>\n",
    "* Mean Absolute Error: 2.16<br>\n",
    "<br>\n",
    "Now we have this total beast of a model that pushed that down even further! This will be our baseline working on the data to see if our model can handle the data that was not included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisit the problem of Data not dropping the NAN\n",
    "Keep in mind that the data we dropped previously was probably of a particular kind. So we would probably have dropped outliers for the model. That said, let's revisit these data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"Life Expectancy Data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.columns = df.columns.str.strip()\n",
    "df['Relative Expenditure'] = df['Total expenditure'] / df['GDP']\n",
    "df = df.drop(labels=['Country','Year','GDP'], axis=1) \n",
    "df['Status'] = df['Status'].apply(lambda x: 1 if x == 'Developing' else 0)\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "imputed_data = imputer.fit_transform(df) # this is also technically cheating for the machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>Adult Mortality</th>\n",
       "      <th>infant deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage expenditure</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>BMI</th>\n",
       "      <th>under-five deaths</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Total expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>Population</th>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <th>thinness 5-9 years</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Schooling</th>\n",
       "      <th>Relative Expenditure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71.279624</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.479</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.013966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59.9</td>\n",
       "      <td>271.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.523582</td>\n",
       "      <td>62.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>327582.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.476</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.013351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59.9</td>\n",
       "      <td>268.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.219243</td>\n",
       "      <td>64.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.470</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.012869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59.5</td>\n",
       "      <td>272.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>78.184215</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2787.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.52</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3696958.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.012717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59.2</td>\n",
       "      <td>275.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.097109</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3013.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>97.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.87</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2978599.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.454</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.123864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Status  Life expectancy  Adult Mortality  infant deaths  Alcohol  \\\n",
       "0     1.0             65.0            263.0           62.0     0.01   \n",
       "1     1.0             59.9            271.0           64.0     0.01   \n",
       "2     1.0             59.9            268.0           66.0     0.01   \n",
       "3     1.0             59.5            272.0           69.0     0.01   \n",
       "4     1.0             59.2            275.0           71.0     0.01   \n",
       "\n",
       "   percentage expenditure  Hepatitis B  Measles   BMI  under-five deaths  \\\n",
       "0               71.279624         65.0   1154.0  19.1               83.0   \n",
       "1               73.523582         62.0    492.0  18.6               86.0   \n",
       "2               73.219243         64.0    430.0  18.1               89.0   \n",
       "3               78.184215         67.0   2787.0  17.6               93.0   \n",
       "4                7.097109         68.0   3013.0  17.2               97.0   \n",
       "\n",
       "   Polio  Total expenditure  Diphtheria  HIV/AIDS  Population  \\\n",
       "0    6.0               8.16        65.0       0.1  33736494.0   \n",
       "1   58.0               8.18        62.0       0.1    327582.0   \n",
       "2   62.0               8.13        64.0       0.1  31731688.0   \n",
       "3   67.0               8.52        67.0       0.1   3696958.0   \n",
       "4   68.0               7.87        68.0       0.1   2978599.0   \n",
       "\n",
       "   thinness  1-19 years  thinness 5-9 years  Income composition of resources  \\\n",
       "0                  17.2                17.3                            0.479   \n",
       "1                  17.5                17.5                            0.476   \n",
       "2                  17.7                17.7                            0.470   \n",
       "3                  17.9                18.0                            0.463   \n",
       "4                  18.2                18.2                            0.454   \n",
       "\n",
       "   Schooling  Relative Expenditure  \n",
       "0       10.1              0.013966  \n",
       "1       10.0              0.013351  \n",
       "2        9.9              0.012869  \n",
       "3        9.8              0.012717  \n",
       "4        9.5              0.123864  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status                             0\n",
      "Life expectancy                    0\n",
      "Adult Mortality                    0\n",
      "infant deaths                      0\n",
      "Alcohol                            0\n",
      "percentage expenditure             0\n",
      "Hepatitis B                        0\n",
      "Measles                            0\n",
      "BMI                                0\n",
      "under-five deaths                  0\n",
      "Polio                              0\n",
      "Total expenditure                  0\n",
      "Diphtheria                         0\n",
      "HIV/AIDS                           0\n",
      "Population                         0\n",
      "thinness  1-19 years               0\n",
      "thinness 5-9 years                 0\n",
      "Income composition of resources    0\n",
      "Schooling                          0\n",
      "Relative Expenditure               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "imputed_df = pd.DataFrame(imputed_data, columns = df.columns)\n",
    "display(imputed_df.head())\n",
    "print(imputed_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = imputed_df.pop('Life expectancy') \n",
    "features = imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = features.select_dtypes(['float64','int64'])\n",
    "numeric_columns = numeric_features.columns\n",
    "ct = ColumnTransformer([(\"Numeric Scaler\", StandardScaler(), numeric_columns)], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, train_size=0.8)\n",
    "X_train_imputed_scaled = ct.fit_transform(X_train)\n",
    "X_test_imputed_scaled = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588/588 [==============================] - 0s 27us/sample - loss: 10.5284 - mae: 2.2058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.528401335891413, 2.2058244]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.evaluate(X_test_imputed_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions, Taking into account more outliers and even letting the model cheat\n",
    "We end up with worse performance if we take in more of the data and even letting the scrip cheat a bit with the imputation we are still worse off. So what happened? We included more outliers in our data and the Viking-model was not prepared for that. It has been trained on a smaller dataset without these missing values. <br>\n",
    " What if we imputed in some other way? That is certainly a good 'hyperparameter' to tweak. There is no real statistics consensus on how to solve complex problems. Is a mean better than cosine? Is the median better than an IterativeImputer using round-robin linear regression, modeling each feature with missing values as a function of other features and assuming Gaussian (output) variables? Well, who can answer that? Iterations, many many many iterations, and experiments. <br>\n",
    "<br>\n",
    " We took the original loss down. We started with a Mean Squared Error loss of about 7.71. The higher complexity model used here called Viking took that down to 5.26. Revisiting the data and expanding brought it up to 10.5 using that higher complexity model. What would be next? Another iteration of what is the best model given all the data. You see the problem is now a different problem. We are still trying to predict the same life expectancy variable but given other data.<br>\n",
    "# Mean Absolute Error Gives us a Clue\n",
    "Now, this was a pretty lenient lesson to learn. We added on about 50% more data and the model on trained on better data got worse on Mean Squared Error that punishes for outliers (see above) but not by a whole lot for mean absolute error that returned to about 2.2 which was our starting error for a lower complexity model. <br>\n",
    "So adding outliers and not training on them produces a result that is worse on outliers, no real surprise.\n",
    "\n",
    "# The really scary outlier cake\n",
    "We have seen that we were mildly punished for not training on outliers here. There is of course something much worse always lurking out there. Always a bigger fish. If we had a model with a year column. And in the year 2016, the earth was hit by a comet on July 1. On June 29th our model would be predicting something reasonable for the next day. However, on June 30th it would not make a good prediction at all. There was one outlier that made all the difference.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
